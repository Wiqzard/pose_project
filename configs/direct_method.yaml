



mode: train  # mode, i.e. train, val, predict,
save_dir:  # path to save directory
dataset_path: /home/bmw/Documents/limemod/lm # path to dataset
debug: True # (bool) enable debug mode

# Train settings -------------------------------------------------------------------------------------------------------
project:  # project name
name: "default"
model:  # path to model file, i.e. yolov8n.pt, yolov8n.yaml
data_path:  # path to dataset
resume:  False # resume training from checkpoint
epochs: 100  # number of epochs to train for
patience: 50  # epochs to wait for no observable improvement for early stopping of training
batch: 32  # number of images per batch (-1 for AutoBatch)
imgsz: [480, 640]  # size of input images as integer or w,h
inp_size: 224
device: 1 # device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
save: True  # save train checkpoints and predict results
save_period: -1 # Save checkpoint every x epochs (disabled if < 1)
optimizer: AdamW  # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
verbose: True  # (bool) whether to print verbose output
cos_lr: False  # (bool) use cosine learning rate scheduler
workers: 1 #8  # (int) number of worker threads for data loading (per RANK if DDP)
plots: True  # (bool) plot training results
shuffle: True # (bool) shuffle dataset 

# Val/Test settings ----------------------------------------------------------------------------------------------------
val: True  # (bool) validate/test during training
split: val  # (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'
save_json: False  # (bool) save results to JSON file
save_hybrid: False  # (bool) save hybrid version of labels (labels + additional predictions)
conf:  # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)
half: False  # (bool) use half precision (FP16)
dnn: False  # (bool) use OpenCV DNN for ONNX inference

# Prediction settings --------------------------------------------------------------------------------------------------
source:  # (str, optional) source directory for images or videos
show: False  # (bool) show results if possible
save_txt: False  # (bool) save results as .txt file

# Hyperparameters ------------------------------------------------------------------------------------------------------
lr0: 0.01  # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
lrf: 0.01  # (float) final learning rate (lr0 * lrf)
momentum: 0.937  # (float) SGD momentum/Adam beta1
weight_decay: 0.0005  # (float) optimizer weight decay 5e-4
warmup_epochs: 3.0  # (float) warmup epochs (fractions ok)
warmup_momentum: 0.8  # (float) warmup initial momentum
warmup_bias_lr: 0.1  # (float) warmup initial bias lr
nbs: 64  # (int) nominal batch size


# Dataset settings
use_obj_bbox: True # (bool) use object bounding box for cropping, otherwise use visble bounding box
num_points: 9000 # (int) number of points to sample from point cloud to feed into pm loss


# Model settings
z_type: rel # (str) type of z to use
trans_type: centroid_z # (str) 
rot_type: allo_rot6d  # {allo/ego}_{quat/rot6d/log_quat/lie_vec}


# Loss settings
num_pm_points: 3000
pm_loss_sym: false  # use symmetric pm loss
pm_r_only: true  # only do r loss in pm
pm_disentangle_t: false  # disentangle r/t
pm_disentangle_z: false  # disentangle r/xy/z
pm_t_use_points: true
pm_lw: 1.0 # (float) weight for poit matching loss

rot_loss_type: "angular"  # angular | l2
rot_lw: 0.0 # (float) weight for angular loss

trans_lw: 0.0 # (flaot) weight for translation loss

centroid_loss_type: "l1" # l1 | l2 | mse
centroid_lw: 1.0 # (float) weight for centroid loss

z_loss_type: "l1" # l1 | l2 | mse
z_lw: 1.0 # (float) weight for z loss


